<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <link rel="stylesheet" href="style.css">
    <title>인공지능</title>
  </head>
  <body>
      <h1><a href="index.html">Artificial Intelligence</a></h1>
        <div id="grid">
    <ol>
      <li><a href="fir.html">인공지능의 적용사례</a></li>
      <li><a href="sec.html" id="active">인공지능의 핵심기술</a></li>
      <li><a href="thr.html">인공지능의 미래</a></li>
  </ol>
    <div id="article">
<h2>인공지능 핵심기술</h2>
<p><strong>1. 초대규모 모델 GPT-3:</strong>

글로벌 테크 기업들은 앞다투어 대규모 모델을 개발하여 성능을 향상시키고 있으며, 2020년 6월 최근에는 초대규모 모델 GPT-3가 공개되었다.

오픈 AI에서는 기존 MS에서 공개했던 Turing LNG 보다 약 10배 정도 더 큰 GPT-3를 공개하면서 시장에 큰 파장을 불러왔다. 시장은 초대규모 모델의 우수한 성능을 인지하기 시작했으며, 초대규모 모델은 API 제공 등 비즈니스 플랫폼 형태로 진화할 전망이다. 많은 정보를 학습한 초대규모 모델은 기존 모델 대비 범용성이 확장된 것을 보여줬다.</p>

<p><strong>2. 연합학습(Federated Learning):</strong>

AI 모델 학습시 데이터를 통합 이동하면서 발생할 수 있는 개인 정보보호 이슈의 부담을 완화할 수 있는 연합학습 개념이 부상했다.
데이터 활용의 증가는 AI 산업의 발전을 이끄는 반면 필연적으로 개인정보보호 이슈가 발생하며, 이러한 제약으로 인해 AI 성능 향상에 한계가 존재한다. 2016년 구글에서 연합학습을 발표한 이후 관련 연구가 폭발적으로 증가하고 있으며 글로벌 테크 기업도 적극적인 연구 개발에 착수했다. 특히 환자의 민감한 개인정보 보호가 중요한 의료 분야에서 대규모 정밀 의학을 가능하게 하는 요소로써 적극 도입되는 추세이다.</p>

<p><strong>3. 엣지 AI(Edge AI):</strong>

클라우드가 글로벌 트렌드로 자리 잡은 상황에서, 클라우드의 중앙집중식 관리 한계를 극복하기 위한 방안으로 엣지 AI 도입이 확대됐다.

전통적으로 빅데이터?AI 서비스는 추론(예측) 시 발생하는 연산량의 한계 때문에 클라우드 환경에서 서비스를 제공한다. 엣지 AI는 데이터 이동이 발생하지 않으므로 중앙집중식 처리에서 발생하는 비용, 속도, 데이터 프라이버시 등의 단점 보완이 가능하다. 다만 적은 메모리와 계산 능력을 보유한 엣지 장치(스마트폰, 차량, 드론 등)의 한계를 극복하고 AI 구현을 하기 위한 신기술 개발이 핵심 이슈이다.</p>

<p><strong>4. 트랜스포머(Transformer):</strong>

트랜스포머는 언어처리의 병렬화를 통해 계산 효율성 향상 등 그간 순차적으로 단어를 학습하는 알고리즘의 한계를 극복한다.
트랜스포머 공개 이후 글로벌 테크 기업들은 모두 트랜스포머 기반의 언어모델을 앞다투어 연구하고 공개하기 시작했다.

컴퓨터 비전 분야는 2012년 이후 전통적으로 CNN7) 기법을 활용해, 모델을 개발해왔으나 최근 NLP의 트랜스포머 방식 도입을 연구 중이다. 향후 트랜스포머는 NLP뿐만 아니라, 컴퓨터 비전 분야에서도 세계 최고 수준의 AI 성능을 제시하는 연구 성과 발표가 기대된다.</p>

<p><strong>5. 시스템2 AI(System2 AI):</strong>

인공지능이 단순 인식이 가능한 ‘시스템 1’ 수준에서 인과관계 파악이 가능한 ‘시스템 2’ 수준으로의 이동을 위한 연구가 활발하다.
요슈아 벤지오(Yoshua Bengio)는 인공지능이 학습되지 않은 상황에서도 맥락을 이해하는 ‘시스템 2’ 추론 중요성을 강조했다. 인공지능의 기대에 비해 현재 인공지능 시스템은 활용 분야가 제한적이고 인과관계 설명이 불충분한 점 등 한계가 있다.

이미지에서 고양이를 인식하거나 음성 명령을 인식하는 것과 같이 ‘시스템 1’ 사고적인 작업에 대해서만 구체적이고 뛰어난 성능을 발휘한다. 인공지능 연구와 신경 과학 연구 분야가 서로 협력하여 발전함으로써 ‘시스템 2’ 사고로의 진화가 이루어질 것이라 예상한다</p>

<p><strong>6. 자기지도학습(Self supervised learning):</strong>

지도학습은 지난 10년 동안 자율주행차, 음성 비서 등 인공지능 분야에서 괄목할만한 발전을 주도했으나, 심각한 한계도 존재한다.
지도학습의 원천이 되는 데이터를 수작업으로 라벨링을 해야하는 번거로움과 비용 부담이 발생하므로 인공지능 개발의 주요 한계가 있다.

얀 르쿤은 비지도 학습의 의미적 모호성 때문에 자기지도학습이라 명명하고, 향후 자기지도학습이 미래 AI 혁신을 주도할 것이라 전망했다. 향후 데이터 라벨링 등 AI 모델링 전 발생하는 노동집약적인 비효율 문제를 개선하기 위해 자기지도학습이 주목받을 전망이다.</p>

<p><strong>7. 생성적 AI(Generativa AI):</strong>

인공지능이 텍스트, 이미지 등 기존 콘텐츠를 사용해 자체적으로 새로운 콘텐츠를 만드는 생성적 AI(Generative AI) 분야가 빠르게 성장했다.

인공지능이 단순히 인지(판별)하는 것을 넘어 입력된 학습 데이터의 패턴을 익혀 해당 데이터 분포와 유사한 콘텐츠를 생성한다. 인공지능 모델을 학습할 때, 부족한 데이터셋을 인위적으로 생성하는 데이터 증강 분야에 활용한다. 다만, 악용될 경우 사회적으로 부정적인 영향을 미칠 우려가 있으므로 기술의 양면성 및 잠재적 파급력에 대한 논의가 확산됐다.</p>

<p><strong>8. 전이학습(Transfer learning):</strong>

전이학습(Transfer learning)은 기존에 학습된 모델의 신경망 일부를 재학습하여 원하는 Task에 맞는 모델을 재생성하는 방법이다.
원하는 Task에 대한 데이터가 부족하거나, 컴퓨팅 자원의 효율적 활용을 위해 기존 모델을 재활용하여 학습한다.

최근 트렌드는 글로벌 테크 기업들이 컴퓨팅 성능을 바탕으로 성능 좋은 모델을 공개하면, 그 모델을 미세 조정하여 사용한다. GPT-3는 API를 통해 수많은 인공지능 서비스를 개발할 수 있도록 지원하는 등 인공지능 모델에서 플랫폼의 역할로 진화 중이다.</p>

<p><strong>9. AutoML:</strong>

머신러닝 개발 과정에서 소모적이고 반복되는 작업을 자동화하는 프로세스인 AutoML(Automated machine learning)의 지속적 부상이다. 현재 인공지능 개발을 위해서는 지속적으로 발생하는 데이터관리, 모델 학습 및 관리 등 많은 자원과 시간이 필요하다.

AutoML은 노동집약적 과정인 머신러닝 모델 개발 작업의 상당 부분을 자동화하며 모델 개발자의 개입을 최소화한다. 3대 클라우드 플랫폼에서도 AutoML 솔루션을 제공하고 있으며, 기업의 수요도 빠르게 증가할 것으로 기대한다.</p>
</div>
</div>
  </body>
</html>
